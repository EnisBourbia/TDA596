package mr

import (
	"encoding/json"
	"fmt"
	"hash/fnv"
	"io/ioutil"
	"log"
	"net/rpc"
	"os"
	"sort"
	"time"
)

// Worker runs the map and reduce tasks assigned by the coordinator.
func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) {
	workerID := os.Getpid() // Use the process ID as a simple unique identifier for the worker.
	for {
		// Request a task from the coordinator.
		taskReply := requestTask(workerID)

		// If the coordinator indicates that all tasks are completed, exit the loop.
		if taskReply.Completed {
			break
		}

		// Handle the task based on its type (Map, Reduce, or Wait).
		switch taskReply.Type {
		case "Map":
			executeMapTask(taskReply, mapf, workerID) // Execute a Map task.
		case "Reduce":
			executeReduceTask(taskReply, reducef, workerID) // Execute a Reduce task.
		case "Wait":
			time.Sleep(time.Second) // No tasks available; wait for a while before retrying.
		default:
			// Unknown task type; sleep and retry later.
			time.Sleep(time.Second)
		}
	}
}

// requestTask sends a request to the coordinator to fetch a task for the worker.
func requestTask(workerID int) TaskReply {
	args := TaskRequest{WorkerID: workerID} // Include the worker ID in the request.
	reply := TaskReply{}
	// Perform an RPC call to request a task.
	call("Coordinator.RequestTask", &args, &reply)
	return reply
}

// executeMapTask performs a map task using the provided map function.
func executeMapTask(task TaskReply, mapf func(string, string) []KeyValue, workerID int) {
	// Read the content of the input file specified in the task.
	content, err := ioutil.ReadFile(task.FileName)
	if err != nil {
		log.Fatalf("Cannot read %v: %v", task.FileName, err)
	}

	// Apply the user-defined map function to generate intermediate key-value pairs.
	kva := mapf(task.FileName, string(content))

	// Partition the intermediate key-value pairs into buckets based on the number of reduce tasks.
	intermediate := make([][]KeyValue, task.NReduce)
	for _, kv := range kva {
		index := ihash(kv.Key) % task.NReduce // Compute the bucket index using a hash function.
		intermediate[index] = append(intermediate[index], kv)
	}

	// Write each bucket to a separate intermediate file.
	for i, kvs := range intermediate {
		filename := fmt.Sprintf("mr-%d-%d", task.TaskID, i) // File format: mr-mapTaskID-reduceBucketID.
		file, err := os.Create(filename)
		if err != nil {
			log.Fatalf("Cannot create %v: %v", filename, err)
		}
		enc := json.NewEncoder(file)
		for _, kv := range kvs {
			err := enc.Encode(&kv) // Serialize the key-value pairs into the file.
			if err != nil {
				log.Fatalf("Cannot write to %v: %v", filename, err)
			}
		}
		file.Close()
	}

	// Notify the coordinator that the map task is completed.
	notifyTaskCompletion("Map", task.TaskID, workerID)
}

// executeReduceTask performs a reduce task using the provided reduce function.
func executeReduceTask(task TaskReply, reducef func(string, []string) string, workerID int) {
	var intermediate []KeyValue // Collect all intermediate key-value pairs.

	// Read intermediate files generated by map tasks for this reduce task.
	for i := 0; i < task.NMap; i++ {
		filename := fmt.Sprintf("mr-%d-%d", i, task.TaskID) // File format: mr-mapTaskID-reduceTaskID.
		file, err := os.Open(filename)
		if err != nil {
			log.Fatalf("Cannot open %v: %v", filename, err)
		}
		dec := json.NewDecoder(file)
		// Decode key-value pairs from the file and add them to the intermediate list.
		for {
			var kv KeyValue
			err := dec.Decode(&kv)
			if err != nil {
				break // Stop when all key-value pairs are read.
			}
			intermediate = append(intermediate, kv)
		}
		file.Close()
	}

	// Sort the intermediate key-value pairs by key to group values for the same key.
	sort.Slice(intermediate, func(i, j int) bool {
		return intermediate[i].Key < intermediate[j].Key
	})

	// Create the output file for the reduce task.
	oname := fmt.Sprintf("mr-out-%d", task.TaskID)
	ofile, err := os.Create(oname)
	if err != nil {
		log.Fatalf("Cannot create %v: %v", oname, err)
	}

	// Perform the reduction:
	// Group values by key and apply the user-defined reduce function.
	i := 0
	for i < len(intermediate) {
		j := i + 1
		// Find the range of key-value pairs with the same key.
		for j < len(intermediate) && intermediate[j].Key == intermediate[i].Key {
			j++
		}
		values := []string{}
		// Collect all values for the current key.
		for k := i; k < j; k++ {
			values = append(values, intermediate[k].Value)
		}
		// Apply the reduce function to compute the result for the current key.
		output := reducef(intermediate[i].Key, values)
		// Write the key and its reduced value to the output file.
		fmt.Fprintf(ofile, "%v %v\n", intermediate[i].Key, output)
		i = j
	}
	ofile.Close()

	// Notify the coordinator that the reduce task is completed.
	notifyTaskCompletion("Reduce", task.TaskID, workerID)
}

// notifyTaskCompletion informs the coordinator that a task has been completed.
func notifyTaskCompletion(taskType string, taskID int, workerID int) {
	args := TaskCompletion{
		Type:     taskType, // Type of the completed task (Map or Reduce).
		TaskID:   taskID,   // ID of the completed task.
		WorkerID: workerID, // ID of the worker that completed the task.
	}
	reply := EmptyReply{}
	// Perform an RPC call to report task completion.
	call("Coordinator.ReportCompletion", &args, &reply)
}

// ihash computes a non-negative hash of a string, used to partition keys into reduce buckets.
func ihash(s string) int {
	h := fnv.New32a() // Create a new hash object.
	h.Write([]byte(s))
	return int(h.Sum32() & 0x7fffffff) // Return a non-negative hash value.
}

// call sends an RPC request to the coordinator.
// It takes the RPC method name, arguments, and a reply structure.
func call(rpcname string, args interface{}, reply interface{}) bool {
	sockname := coordinatorSock() // Get the socket name of the coordinator.
	client, err := rpc.DialHTTP("unix", sockname)
	if err != nil {
		log.Fatalf("Dialing error: %v", err)
	}
	defer client.Close()

	// Perform the RPC call.
	err = client.Call(rpcname, args, reply)
	return err == nil // Return true if the call was successful, false otherwise.
}
